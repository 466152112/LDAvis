% Generated by roxygen2 (4.0.2): do not edit by hand
\name{createJSON}
\alias{createJSON}
\title{Create the JSON object to read into the javascript visualization}
\usage{
createJSON(phi = matrix(), theta = matrix(), alpha = numeric(),
  beta = numeric(), doc.length = integer(), vocab = character(),
  term.frequency = integer(), R = 30, lambda.seq = seq(0, 1, by = 0.01),
  mds.method = jsPCA, cluster, plot.opts = list(xlab = "PC1", ylab = "PC2",
  ticks = FALSE), ...)
}
\arguments{
  \item{phi}{matrix, with each row containing the
  distribution over terms for a topic, with as many rows as
  there are topics in the model, and as many columns as
  there are terms in the vocabulary.}

  \item{theta}{matrix, with each row containing the
  probability distribution over topics for a document, with
  as many rows as there are documents in the corpus, and as
  many columns as there are topics in the model.}

  \item{alpha}{numeric vector with as many elements as
  there are topics in the model, containing the parameters
  of the Dirichlet prior distribution over topics for each
  document.}

  \item{beta}{numeric vector with as many elements as there
  are terms in the vocabulary, containing the parameters of
  the Dirichlet prior distribution over terms for each
  topic.}

  \item{doc.length}{integer vector containing the number of
  tokens in each document of the corpus.}

  \item{vocab}{character vector of the terms in the
  vocabulary (in the same order as the columns of
  \code{phi} and the elements of \code{beta}).}

  \item{term.frequency}{integer vector containing the
  frequency of each term in the vocabulary.}

  \item{R}{integer, the number of terms to display in the
  barcharts of the interactive viz. Default is 30.
  Recommended to be roughly between 10 and 50.}

  \item{lambda.seq}{a sequence of values (for lambda) from
  0 to 1.}

  \item{mds.method}{a function that takes \code{phi} as an
  input and outputs a K by 2 data.frame (or matrix). The
  output approximates the distance between topics. See
  \link{jsPCA} for details on the default method.}

  \item{cluster}{a cluster object created from the
  \link{parallel} package. If supplied, computations are
  performed using \link{parallel::parLapply} instead of
  \link{lapply}.}

  \item{plot.opts}{a named list used to customize various
  plot elements. By default, the x and y axes are labeled
  "PC1" and "PC2" (principal components 1 and 2), since
  \link{jsPCA} is the default scaling method.}
}
\value{
A string containing JSON content which can be written to a
file or feed into \link{serVis} for easy viewing/sharing.
}
\description{
This function creates the JSON object that feeds the
visualization template. For a more detailed overview, see
\code{vignette("details", package = "LDAvis")}
}
\details{
The function first computes the topic frequencies (across
the whole corpus), and then it reorders the topics in
decreasing order of frequency. The main computation is to
loop through the topics and through 101 values of lambda
(0, 0.01, 0.02, .., 1) to compute the \code{R} most
\emph{relevant} terms for each topic and value of lambda.
If \code{quiet = FALSE} progress in this loop (which can
take a minute or two) will print to the screen.
}
\examples{
# This example uses news article data from D = 2246 Associated Press
# articles tokenized and shared by David Blei:
# http://www.cs.princeton.edu/~blei/lda-c/index.html
\dontrun{
# load the AP data:
data(AP, package="LDAvis")

# create the json object:
json <- with(AP, createJSON(phi, theta, alpha, beta, doc.length,
                   vocab, term.frequency))
serVis(json) # press ESC or Ctrl-C to kill

# You may want to just write the JSON and other dependency files
# to a folder named AP under the working directory
serVis(json, out.dir = 'AP', open.browser = FALSE)
# then you could use a server of your choice
system("cd AP && python -m SimpleHTTPServer", wait = FALSE)
browseURL("http://localhost:8000")

# If you have a GitHub account, you can even publish as a gist
# which allows you to easily share with others!
serVis(json, as.gist = TRUE)

# Run createJSON on a cluster of machines to speed it up
system.time(
json <- with(AP, createJSON(phi, theta, alpha, beta, doc.length,
                   vocab, term.frequency))
)
#   user  system elapsed
#  8.701   0.475   9.342
library("parallel")
cl <- makeCluster(detectCores()-1)
cl # socket cluster with 7 nodes on host ‘localhost’
system.time(
json <- with(AP, createJSON(phi, theta, alpha, beta, doc.length,
                   vocab, term.frequency, cluster = cl))
)
#   user  system elapsed
#  1.696   0.281   4.895

# why does this freeze up? Too many dimensions?
#library("tsne")
#json <- with(AP, createJSON(phi, theta, alpha, beta, doc.length,
#                vocab, term.frequency, mds.method = tsne))
#serVis(json)

}
}
\references{
Sievert, C. and Shirley, K. (2014) \emph{LDAvis: A Method
for Visualizing and Interpreting Topics}, ACL Workshop on
Interactive Language Learning, Visualization, and
Interfaces.
\url{http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf}
}
\seealso{
\link{serVis}
}

